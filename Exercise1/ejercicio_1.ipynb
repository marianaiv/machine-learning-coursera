{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise 1: Linear Regression\n",
    "\n",
    "Before we begin with the exercises, we need to import all libraries required for this programming exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils \n",
    "\n",
    "# define the submission/grader object for this exercise\n",
    "grader = utils.Grader()\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Simple python and `numpy` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, you will find the outline of a `python` function. Modify it to return a 5 x 5 identity matrix by filling in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmUpExercise():\n",
    "    \"\"\"\n",
    "    Example function in Python which computes the identity matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A : array_like\n",
    "        The 5x5 identity matrix.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Return the 5x5 identity matrix.\n",
    "    \"\"\"    \n",
    "    # ======== YOUR CODE HERE ======\n",
    "    \n",
    "    A = np.eye(5)  \n",
    "    \n",
    "    # ==============================\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous cell only defines the function `warmUpExercise`. We can now run it by executing the following cell to see its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmUpExercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Linear regression with one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `Data/ex1data1.txt` contains the dataset for our linear regression problem. The first column is the population of a city (in 10,000s) and the second column is the profit of a food truck in that city (in $10,000s). A negative value for profit indicates a loss. \n",
    "\n",
    "We provide you with the code needed to load this data. The dataset is loaded from the data file into the variables `x` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read comma separated data\n",
    "data = np.loadtxt(os.path.join('Data', 'ex1data1.txt'), delimiter=',')\n",
    "X, y = data[:, 0], data[:, 1]\n",
    "\n",
    "m = y.size  # number of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Plotting the Data\n",
    "\n",
    "In the following part, your first job is to complete the `plotData` function below. Modify the function and fill in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(X, y):\n",
    "    \"\"\"\n",
    "    Plots the data points x and y into a new figure. Plots the data \n",
    "    points and gives the figure axes labels of population and profit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Data point values for x-axis.\n",
    "\n",
    "    y : array_like\n",
    "        Data point values for y-axis. Note x and y should have the same size.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Plot the training data into a figure using the \"figure\" and \"plot\"\n",
    "    functions. Set the axes labels using the \"xlabel\" and \"ylabel\" functions.\n",
    "    Assume the population and revenue data have been passed in as the x\n",
    "    and y arguments of this function.    \n",
    "    \n",
    "    Hint\n",
    "    ----\n",
    "    You can use the 'ro' option with plot to have the markers\n",
    "    appear as red circles. Furthermore, you can make the markers larger by\n",
    "    using plot(..., 'ro', ms=10), where `ms` refers to marker size. You \n",
    "    can also set the marker edge color using the `mec` property.\n",
    "    \"\"\"\n",
    "    fig = pyplot.figure()  # open a new figure\n",
    "    \n",
    "    # ====================== YOUR CODE HERE ======================= \n",
    "    \n",
    "    pyplot.plot(X, y, 'ob', mec='k')\n",
    "    pyplot.ylabel('Profit ($10K)')\n",
    "    pyplot.xlabel('Population of the city (10K)')\n",
    "    \n",
    "    # =============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotData(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gradient Descent\n",
    "\n",
    "In this part, you will fit the linear regression parameters $\\theta$ to our dataset using gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already set up the data for linear regression. In the following cell, we add another dimension to our data to accommodate the $\\theta_0$ intercept term. Do NOT execute this cell more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of ones to X. The numpy function stack joins arrays along a given axis. \n",
    "# The first axis (axis=0) refers to rows (training examples) \n",
    "# and second axis (axis=1) refers to columns (features).\n",
    "X = np.stack([np.ones(m), X], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to complete the code for the function `computeCost` which computes $J(\\theta)$. As you are doing this, remember that the variables $X$ and $y$ are not scalar values. $X$ is a matrix whose rows represent the examples from the training set and $y$ is a vector whose each elemennt represent the value at a given row of $X$.\n",
    "<a id=\"computeCost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute cost for linear regression. Computes the cost of using theta as the\n",
    "    parameter for linear regression to fit the data points in X and y.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n+1), where m is the number of examples,\n",
    "        and n is the number of features. We assume a vector of one's already \n",
    "        appended to the features so we have n+1 columns.\n",
    "    \n",
    "    y : array_like\n",
    "        The values of the function at each data point. This is a vector of\n",
    "        shape (m, ).\n",
    "    \n",
    "    theta : array_like\n",
    "        The parameters for the regression function. This is a vector of \n",
    "        shape (n+1, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The value of the regression cost function.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the cost of a particular choice of theta. \n",
    "    You should set J to the cost.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    J = 0\n",
    "    \n",
    "    # ====================== YOUR CODE HERE =====================\n",
    "    \n",
    "    h = X.dot(theta)\n",
    "    \n",
    "    J = 1/(2*m)*np.sum(np.square(h-y))\n",
    "    \n",
    "    # ===========================================================\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed the function, the next step will run `computeCost` two times using two different initializations of $\\theta$. You will see the cost printed to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With theta = [0, 0] \n",
      "Cost computed = 32.07\n",
      "Expected cost value (approximately) 32.07\n",
      "\n",
      "With theta = [-1, 2]\n",
      "Cost computed = 54.24\n",
      "Expected cost value (approximately) 54.24\n"
     ]
    }
   ],
   "source": [
    "J = computeCost(X, y, theta=np.array([0, 0]))\n",
    "print('With theta = [0, 0] \\nCost computed = %.2f' % J)\n",
    "print('Expected cost value (approximately) 32.07\\n')\n",
    "\n",
    "\n",
    "# further testing of the cost function+6\n",
    "J = computeCost(X, y, theta=np.array([-1, 2]))\n",
    "print('With theta = [-1, 2]\\nCost computed = %.2f' % J)\n",
    "print('Expected cost value (approximately) 54.24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will complete a function which implements gradient descent.\n",
    "The loop structure has been written for you, and you only need to supply the updates to $\\theta$ within each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn `theta`. Updates theta by taking `num_iters`\n",
    "    gradient steps with learning rate `alpha`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n+1).\n",
    "    \n",
    "    y : arra_like\n",
    "        Value at given features. A vector of shape (m, ).\n",
    "    \n",
    "    theta : array_like\n",
    "        Initial values for the linear regression parameters. \n",
    "        A vector of shape (n+1, ).\n",
    "    \n",
    "    alpha : float\n",
    "        The learning rate.\n",
    "    \n",
    "    num_iters : int\n",
    "        The number of iterations for gradient descent. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        The learned linear regression parameters. A vector of shape (n+1, ).\n",
    "    \n",
    "    J_history : list\n",
    "        A python list for the values of the cost function after each iteration.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Peform a single gradient step on the parameter vector theta.\n",
    "\n",
    "    While debugging, it can be useful to print out the values of \n",
    "    the cost function (computeCost) and gradient here.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0]  # number of training examples\n",
    "    \n",
    "    # make a copy of theta, to avoid changing the original array, since numpy arrays\n",
    "    # are passed by reference to functions\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = [] # Use a python list to save cost in every iteration\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # ==================== YOUR CODE HERE =================================\n",
    "        \n",
    "        h = X.dot(theta)\n",
    "        theta = theta - alpha*(1/m)*np.sum(np.dot(h-y, X))\n",
    "        \n",
    "        # =====================================================================\n",
    "        \n",
    "        # save the cost J in every iteration\n",
    "        J_history.append(computeCost(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you are finished call the implemented `gradientDescent` function and print the computed $\\theta$. We initialize the $\\theta$ parameters to 0 and the learning rate $\\alpha$ to 0.01. Execute the following cell to check your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta found by gradient descent: 0.7209, 0.7209\n",
      "Expected theta values (approximately): [-3.6303, 1.1664]\n"
     ]
    }
   ],
   "source": [
    "# initialize fitting parameters\n",
    "theta = np.zeros(2)\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "theta, J_history = gradientDescent(X ,y, theta, alpha, iterations)\n",
    "print('Theta found by gradient descent: {:.4f}, {:.4f}'.format(*theta))\n",
    "print('Expected theta values (approximately): [-3.6303, 1.1664]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
